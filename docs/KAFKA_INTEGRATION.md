# Kafka Integration - analytics-and-dashboards

Este documento describe la integraci√≥n de Apache Kafka en el microservicio `analytics-and-dashboards`, adaptada desde la implementaci√≥n en Node.js del repositorio `beats-interaction`.

## üìã Resumen de cambios

### Archivos creados

- **`app/services/kafka_consumer.py`**: Servicio principal de Kafka que maneja la conexi√≥n, consumo y producci√≥n de mensajes

### Archivos modificados

1. **`app/core/config.py`**: Agregadas variables de configuraci√≥n para Kafka
2. **`main.py`**: Integraci√≥n del servicio Kafka en el ciclo de vida de la aplicaci√≥n
3. **`app/endpoints/health.py`**: Nuevo endpoint de health check para Kafka
4. **`.env.example`**: Agregadas variables de entorno para Kafka
5. **`docker-compose.yml`**: Agregados servicios de Zookeeper y Kafka
6. **`requirements.txt`**: Agregada dependencia `aiokafka==0.11.0`

## üöÄ Caracter√≠sticas implementadas

### 1. Servicio Kafka (`kafka_consumer.py`)

El servicio incluye las siguientes caracter√≠sticas principales (alineadas con `kafkaConsumer.js`):

- **Conexi√≥n con reintentos infinitos**: Loop infinito que reintenta la conexi√≥n con delays configurables
- **Per√≠odo de cooldown**: Despu√©s de agotar los reintentos m√°ximos, entra en cooldown antes de reiniciar
- **Consumer y Producer**: Ambos clientes configurados con `clientId` para identificaci√≥n
- **Admin Client**: Funci√≥n `is_kafka_connected()` para verificar conectividad
- **Dead Letter Queue (DLQ)**: Los mensajes que fallan se env√≠an al topic `analytics-dlq`
- **Procesamiento de eventos**: Parseo autom√°tico de JSON y manejo de errores
- **Procesamiento as√≠ncrono**: Utiliza asyncio para operaciones no bloqueantes
- **C√°lculo autom√°tico de m√©tricas**: Escucha el topic `beats-events` y procesa eventos `BEAT_CREATED` para calcular m√©tricas autom√°ticamente

#### Event Handlers Implementados

##### `BEAT_CREATED`

Cuando el microservicio `beats-upload` publica un beat nuevo, se env√≠a un evento por Kafka que este servicio consume autom√°ticamente para calcular las m√©tricas del beat.

**Estructura del evento esperado:**

```json
{
  "type": "BEAT_CREATED",
  "payload": {
    "beatId": "507f1f77bcf86cd799439011",
    "audioUrl": "https://s3.amazonaws.com/bucket/audio.mp3",
    "userId": "507f191e810c19729de860ea"
  }
}
```

**Flujo de procesamiento:**

1. El consumer recibe el evento del topic `beats-events`
2. Extrae `beatId`, `audioUrl` y `userId` del payload
3. Descarga el archivo de audio desde `audioUrl`
4. Analiza el audio con librosa y extrae m√©tricas (BPM, key, energy, etc.)
5. Guarda las m√©tricas en MongoDB en la colecci√≥n `beat_metrics`
6. Si hay error, env√≠a el evento al DLQ (`analytics-dlq`)

**Diferencias con la versi√≥n Node.js:**

- Usa `aiokafka` (Python) en lugar de `kafkajs` (Node.js)
- Implementa el caso de negocio `BEAT_CREATED` espec√≠fico para este microservicio
- Se puede extender con m√°s handlers en `_process_event()`

### 2. Configuraci√≥n

Nuevas variables en `app/core/config.py`:

```python
KAFKA_BROKER: str = "localhost:9092"
ENABLE_KAFKA: bool = True
KAFKA_CONNECTION_MAX_RETRIES: int = 10
KAFKA_CONNECTION_RETRY_DELAY: int = 3000  # milliseconds
KAFKA_COOLDOWN: int = 30000  # milliseconds
```

### 3. Endpoints

**GET `/api/v1/kafka/health`**

Verifica el estado de la conexi√≥n a Kafka.

Respuesta exitosa (200):

```json
{
  "kafka": "connected",
  "in_cooldown": false,
  "retry_count": 0,
  "enabled": true,
  "timestamp": "2025-12-09T10:30:00.000000"
}
```

Respuesta fallida (503):

```json
{
  "kafka": "disconnected",
  "in_cooldown": false,
  "retry_count": 5,
  "enabled": true,
  "timestamp": "2025-12-09T10:30:00.000000"
}
```

## üê≥ Docker Compose

Se agregaron dos nuevos servicios:

### Zookeeper

```yaml
zookeeper:
  image: confluentinc/cp-zookeeper:7.5.0
  ports:
    - "2181:2181"
```

### Kafka

```yaml
kafka:
  image: confluentinc/cp-kafka:7.5.0
  ports:
    - "9092:9092"
    - "9093:9093"
```

## üì¶ Instalaci√≥n

### Desarrollo local

1. Instalar dependencias:

```bash
pip install -r requirements.txt
```

2. Configurar variables de entorno (copiar desde `.env.example`):

```bash
cp .env.example .env
```

3. Iniciar Kafka y Zookeeper (requiere Docker):

```bash
docker-compose up -d zookeeper kafka
```

4. Iniciar la aplicaci√≥n:

```bash
python main.py
```

### Con Docker Compose

```bash
docker-compose up --build
```

## üîß Configuraci√≥n de entorno

Variables de entorno necesarias:

```env
# Kafka Configuration
KAFKA_BROKER="localhost:9092"
ENABLE_KAFKA=true
KAFKA_CONNECTION_MAX_RETRIES=10
KAFKA_CONNECTION_RETRY_DELAY=3000
KAFKA_COOLDOWN=30000
```

Para entornos Docker, usar el nombre del servicio:

```env
KAFKA_BROKER="kafka:29092"
```

## üéØ Uso del servicio Kafka

### Consumir mensajes

El consumer se inicia autom√°ticamente cuando la aplicaci√≥n arranca y escucha el topic `beats-events` para procesar eventos de beats.

#### Event Handler: BEAT_CREATED

El servicio est√° configurado para procesar autom√°ticamente eventos `BEAT_CREATED` que env√≠a el microservicio `beats-upload`. Cuando se recibe este evento:

1. Descarga el archivo de audio desde la URL proporcionada
2. Analiza las caracter√≠sticas del audio (BPM, key, energy, etc.)
3. Calcula las m√©tricas core y extra
4. Guarda los resultados en la base de datos MongoDB

**No se requiere intervenci√≥n manual** - el proceso es completamente autom√°tico.

#### Agregar m√°s handlers

Para procesar eventos personalizados adicionales, agrega m√°s casos en el m√©todo `_process_event` en `kafka_consumer.py`:

```python
async def _process_event(self, event: dict):
    """Process individual Kafka events"""
    event_type = event.get("type", "UNKNOWN")
    
    if event_type == "BEAT_CREATED":
        await self._handle_beat_created(event.get("payload"))
    elif event_type == "METRIC_UPDATED":
        # Tu l√≥gica aqu√≠
        await self._handle_metric_updated(event.get("payload"))
    elif event_type == "DASHBOARD_REFRESH":
        # Tu l√≥gica aqu√≠
        await self._handle_dashboard_refresh(event.get("payload"))
    else:
        logger.info(f"Unhandled event type: {event_type}")
```

**Formato esperado de eventos:**

```json
{
  "type": "EVENT_TYPE",
  "payload": {
    // tus datos aqu√≠
  }
}
```

### Subscribirse a topics

El servicio ya est√° configurado para escuchar el topic `beats-events`. Si necesitas agregar m√°s topics:

```python
# En start_kafka_consumer(), despu√©s de await self.consumer.start()
self.consumer.subscribe(["beats-events", "metrics-events", "analytics-events"])
```

### Enviar mensajes

```python
from app.services.kafka_consumer import kafka_service
import json

# Enviar un evento
event = {
    "type": "METRIC_CALCULATED",
    "payload": {"metric": "cpu_usage", "value": 75.5}
}

await kafka_service.send_message(
    topic='analytics-events',
    message=json.dumps(event).encode('utf-8'),
    key=b'metric-123'
)
```

### Dead Letter Queue (DLQ)

Los mensajes que no se pueden procesar correctamente se env√≠an autom√°ticamente al topic `analytics-dlq` con la siguiente estructura:

```json
{
  "originalEvent": "mensaje original que fall√≥",
  "error": "raz√≥n del error",
  "timestamp": "2025-12-09T10:30:00.000000"
}
```

### Verificar estado de conexi√≥n

```python
# M√©todo 1: Health check r√°pido
health = await kafka_service.check_health()
print(health)

# M√©todo 2: Verificaci√≥n completa con admin client
is_connected = await kafka_service.is_kafka_connected()
print(f"Kafka connected: {is_connected}")
```

## üîÑ L√≥gica de reintentos

La l√≥gica de reintentos replica el comportamiento de `kafkaConsumer.js`:

1. **Intento inicial**: La aplicaci√≥n intenta conectarse a Kafka al iniciar
2. **Reintentos con delay**: Si falla, reintenta hasta `KAFKA_CONNECTION_MAX_RETRIES` veces con un delay de `KAFKA_CONNECTION_RETRY_DELAY` ms entre intentos
3. **Cooldown**: Despu√©s de agotar los reintentos, espera `KAFKA_COOLDOWN` ms antes de volver al paso 1
4. **Loop infinito**: Este proceso contin√∫a indefinidamente hasta lograr una conexi√≥n exitosa

Esta estrategia asegura que:

- No se sature el broker con intentos excesivos
- La aplicaci√≥n pueda recuperarse autom√°ticamente de ca√≠das temporales de Kafka
- Se proporcione tiempo suficiente para que Kafka se reinicie si est√° down

**Ejemplo de logs durante reconexi√≥n:**

```
INFO: Connecting to Kafka... (Attempt 1/10)
ERROR: Kafka connection failed: Connection refused
WARNING: Retrying in 3.0s...
INFO: Connecting to Kafka... (Attempt 2/10)
...
WARNING: Max retries reached. Cooling down for 30.0s before trying again...
```

## üêõ Troubleshooting

### Kafka no se conecta

1. Verificar que Zookeeper y Kafka est√©n ejecut√°ndose:

```bash
docker-compose ps
```

2. Revisar logs de Kafka:

```bash
docker-compose logs kafka
```

3. Verificar la configuraci√≥n del broker en `.env`

### Endpoint de health devuelve "disconnected"

- Verificar la variable `ENABLE_KAFKA` est√° en `true`
- Comprobar que el broker es accesible desde la aplicaci√≥n
- Revisar los logs de la aplicaci√≥n para errores de conexi√≥n

## üìö Referencias

- Commit original de Node.js: [14129db](https://github.com/SocialBeats/beats-interaction/commit/14129db275d8f158a4ed1dc68e6821ec7df990f7)
- Documentaci√≥n de aiokafka: <https://aiokafka.readthedocs.io/>
- Apache Kafka: <https://kafka.apache.org/documentation/>

## ‚úÖ Checklist de implementaci√≥n

- [x] Crear servicio Kafka consumer
- [x] Agregar configuraci√≥n en `config.py`
- [x] Integrar en el lifecycle de FastAPI
- [x] Crear endpoint de health check
- [x] Actualizar docker-compose con Zookeeper y Kafka
- [x] Actualizar `.env.example`
- [x] Agregar dependencia en `requirements.txt`
- [x] Documentaci√≥n completa
- [x] Implementar handler para evento `BEAT_CREATED`
- [x] Subscribirse al topic `beats-events`
- [x] Integrar con `BeatMetricsService` para c√°lculo autom√°tico

## üîú Pr√≥ximos pasos

1. **Instalar dependencias**:

   ```bash
   pip install -r requirements.txt
   ```

2. **Iniciar servicios Docker**:

   ```bash
   docker-compose up -d zookeeper kafka
   ```

3. **Configurar el microservicio `beats-upload`**:
   - Implementar publicaci√≥n de eventos `BEAT_CREATED` al topic `beats-events`
   - Incluir `beatId`, `audioUrl` y `userId` en el payload

4. **Testing del flujo completo**:
   - Subir un beat desde `beats-upload`
   - Verificar que el evento se publique a Kafka
   - Confirmar que `analytics-and-dashboards` consume el evento
   - Validar que las m√©tricas se calculen y guarden correctamente

5. **Implementar handlers adicionales** (opcional):
   - Agregar m√°s tipos de eventos seg√∫n necesidades del negocio
   - Ejemplo: `BEAT_DELETED`, `BEAT_UPDATED`, etc.

6. **Monitoreo y DLQ**:
   - Monitorear el topic `analytics-dlq` para mensajes fallidos
   - Implementar dashboard o alertas para errores

7. **M√©tricas y observabilidad**:
   - Implementar m√©tricas de mensajes procesados/fallidos
   - Dashboard de salud de Kafka
   - Alertas en caso de desconexi√≥n prolongada

8. **Seguridad** (producci√≥n):
   - Configurar SASL/SSL para conexi√≥n segura
   - Implementar ACLs en Kafka
